{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game: AddItUp\n",
    "## Rules:\n",
    "* On each turn, each player picks a number between 1 and 5.\n",
    "* After 100 turns, each player adds up all the numbers they chose.\n",
    "* The player with the higher total wins.\n",
    "\n",
    "## Task 1:\n",
    "\n",
    "* select any of the five options with equal probability\n",
    "* repeat for 100 times\n",
    "* plot a histogram of your choices\n",
    "* repeat 5 times and compare the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "policy = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "for i in range(100):\n",
    "    choice = #YOUR_CODE_HERE\n",
    "    counts[choice] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "* implement the game AddItUp for two players (using one for loop only)\n",
    "* implement it as function “simulate_game” taking a policy vector as parameter\n",
    "* policy vector is a probability distribution, eg. np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "* return a tuple of dicts for winner and looser choices like {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game(policy):\n",
    "    \"\"\"Returns a tuple of (winning choices, losing choices)\"\"\"\n",
    "    player_1_choices = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    player_1_total = 0\n",
    "    player_2_choices = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    player_2_total = 0\n",
    "    for i in range(100):\n",
    "        ## YOUR_CODE_HERE\n",
    "    return (winner_choices, loser_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "simulate_game(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "* after each game, count the net_wins per choice\n",
    "     * how often was the choice involved in a winning choice/action trajectory minus how often was the choice involved in a loosing choice/action trajectory\n",
    "* adjust the policy vector for each choice accordingly (using learning rate 0.0001)\n",
    "    * by adding the net wins multiplicated by the learning rate to the policy (per choice)\n",
    "    * by then re-normalizing the policy\n",
    "    * in other words, good choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(policy):\n",
    "    policy = np.clip(policy, 0, 1)\n",
    "    return policy / np.sum(policy)\n",
    "\n",
    "choices = [1, 2, 3, 4, 5]\n",
    "policy = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "learning_rate = 0.0001\n",
    "num_games = 10000\n",
    "for i in range(num_games):\n",
    "    win_counts, lose_counts = simulate_game(policy)\n",
    "    for i, choice in enumerate(choices):\n",
    "        ## YOUR_CODE_HERE\n",
    "    policy = normalize(policy)\n",
    "    print('%d: %s' % (i, policy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Difference between  Add It Up and Go: \n",
    "\n",
    "* The policy used in Add It Up doesn’t depend on the game state\n",
    "\n",
    "* In Go, the policy depends on the situation (state) and similar situations should create a similar policy. We rely on the power of neural networks here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
